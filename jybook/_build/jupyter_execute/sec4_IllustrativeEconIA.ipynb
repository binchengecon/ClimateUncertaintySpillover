{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62734c98",
   "metadata": {},
   "source": [
    "The notebooks proceed with three example economies with different features:\n",
    "\n",
    "- the first one features damage function uncertainty and its resolution (demostrated in this notebook);\n",
    "    - a suppliment to the discussion of $\\xi_r$, we also demonstrate the impact of smooth ambiguity $\\xi_a$ in the following notebook ([Section 4.3 smooth ambiguity](sec4_IllustrativeEconIB.ipynb));\n",
    "- the second features a novel uncertainty decomposition that incorporates robustness to model ambiguity and misspecification ([Section 5](sec5_IllustrativeEconII.ipynb));\n",
    "- the investigates the impact of uncertain advances in the availability of less carbon-intensive technologies ([Section 6](sec6_IllustrativeEconIII.ipynb)).\n",
    "\n",
    "# 4 Illustrative economy I\n",
    "\n",
    "\n",
    "We pose  an  $AK$ technology for which output is\n",
    "proportional to capital and can be allocated  between investment  and consumption. Capital in this specification should be broadly conceived. Suppose that there are adjustment costs to capital that are represented as the product of capital\n",
    "times a quadratic function of the investment-capital ratio.\n",
    "Given the output constraint and capital evolution imposed by  the $AK$ technology, it suffices to let  the planner choose the\n",
    "investment-capital ratio.\n",
    "\n",
    "\n",
    "Formally, \"undamaged\" capital evolves as\n",
    "\n",
    "$$\n",
    "d K_t =  K_t   \\left[ \\mu_k (Z_t) dt + \\left({\\frac {I_t}{K_t}} \\right)dt - {\\frac { \\kappa} 2} \\left( {\\frac {I_t} {K_t}} \\right)^2 dt\n",
    "+ \\sigma_k(Z_t) dW_t^k \\right]\n",
    "$$\n",
    "\n",
    "where $K_t$ is the capital stock and $I_t$ is investment.\n",
    "The capital evolution expressed in logarithms is\n",
    "\n",
    "$$\n",
    "d\\log K_t =  \\left[ \\mu_k (Z_t)    + \\left({\\frac {I_t}{K_t}} \\right)  -\n",
    "{\\frac { \\kappa} 2} \\left( {\\frac {I_t} {K_t}} \\right)^2 \\right] dt -  {\\frac  {\\vert \\sigma_k(Z_t) \\vert^2}  2}dt+ \\sigma_k(Z_t) dW_t^k ,\n",
    "$$\n",
    "\n",
    "The sum of consumption, $C_t$, and investment, $I_t$, are constrained to be proportional to capital:\n",
    "\n",
    "$$\n",
    "C_t + I_t = \\alpha K_t\n",
    "$$\n",
    "\n",
    "\n",
    "Next, we consider environmental damages.\n",
    "We suppose that temperature shifts proportionately consumption and capital by a multiplicative factor\n",
    "$N_t$  that captures damages to the productive capacity induced by climate change.  For instance, the\n",
    "damage adjusted consumption is ${\\widetilde C}_t =  {\\frac {C_t}{N_t}}$ and the damage adjusted capital is ${\\widetilde K}_t = {\\frac {{K}_t }{N_t}}$.  \n",
    "\n",
    "\n",
    "Planner preferences are time-separable with  a unitary elasticity of substitution. The planner's instantaneous utility from \"damaged consumption\" and emissions is given by:\n",
    "\n",
    "\\begin{align*}\n",
    "&  (1-\\eta) \\log {\\tilde C}_t +  \\eta \\log {\\mathcal E}_t   \\cr & = (1-\\eta)( \\log C_t -\\log K_t ) +  (1-\\eta)( \\log K_t - \\log N_t)   + \\eta \\log {\\mathcal E}_t\n",
    "\\end{align*}\n",
    "\n",
    "We let $\\delta$ be the subjective rate of discount used in preferences.\n",
    "We can think of emissions and consumption as distinct goods, or we can think of $\\widetilde{C}_t$ as an intermediate good that when combined with emissions determines final consumption.\n",
    "\n",
    "\n",
    ">**Note**\n",
    "> \n",
    ">*We obtain a further simplication by letting:*\n",
    ">\n",
    ">$$\\widetilde{\\mathcal{E}}_t = \\mathcal{E}_t (\\iota_y \\cdot Z_t)$$\n",
    ">\n",
    ">*We use $\\widetilde{\\mathcal{E}}_t$ as the control variable and then deduce the implications for $\\mathcal{E}_t$*.\n",
    "\n",
    "\n",
    "## 4.1 HJB equations and robustness\n",
    "\n",
    "The uncertainty that we consider has a single jump point after which the damage function uncertainty is revealed.  This leads us to compute continuation value functions conditioned on each of the damage function specifications.  These continuation value functions then are used to summarize post-jump outcomes when we compute the initial value function.  We describe the Hamilton-Jacobi-Bellman (HJB) equations for each of these steps in what follows. The computational methods are described in the [appendix B](appendixB.ipynb).\n",
    "\n",
    "\n",
    "The parameter values are as follows:\n",
    "\n",
    "| Parameters | values |\n",
    "| :---:| :---|\n",
    "|$\\delta$ |  0.01 |\n",
    "|$\\eta$ | 0.032 | \n",
    "|$\\varsigma'$| [2.23, 0, 0]|\n",
    "\n",
    "Damage parameters are described in [section 3](sec3_UncertainDamage.ipynb).\n",
    "\n",
    "\n",
    "### 4.1.1 Post-jump continuation value functions\n",
    "\n",
    "\n",
    "Conditioned on each of the damage functions, $m = 1, 2, \\dots, 20$. Solve for the corresponding $\\phi_m(y)$:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "0 = \\max_{\\tilde e}  \\min_h \\min_{\\omega_j, \\sum_{\\ell =1}^L \\omega_\\ell  = 1}\n",
    "& - \\delta \\phi_m(y)    +  \\eta \\log \\tilde e    \\cr\n",
    "& + \\frac {d \\phi_m(y)}{d y} {\\tilde e}  \\varsigma \\cdot h  + {\\frac {(\\eta - 1)} \\delta }\\left[\\gamma_1 +  \\gamma_2 y + \\gamma_3^m (y- {\\overline y} ) \\right] {\\tilde e} \\varsigma \\cdot h + {\\frac {\\xi_r} 2} h'h \\cr \n",
    "& + \\frac {d \\phi_m(y)}{d y}  \\sum_{\\ell=1}^L \\omega_\\ell  \\theta_\\ell {\\tilde e} + {\\frac 1 2} \\frac {d^2 \\phi_m(y)}{(dy)^2} |\\varsigma|^2 \\tilde e^2  \\cr\n",
    "&+ {\\frac {(\\eta - 1)} \\delta}  \\left( \\left[ \\gamma_1 + \\gamma_2 y + \\gamma_3^m (y - \\overline y) \\right]   \\sum_{\\ell=1}^L \\omega_\\ell \\theta_\\ell {\\tilde e} + {\\frac 1 2} (\\gamma_2 + \n",
    "\\gamma_3^m) |\\varsigma|^2 \\tilde e^2 \\right) \\cr\n",
    "&+ \\xi_a \\sum_{\\ell = 1}^L \\omega_\\ell \\left( \\log \\omega_\\ell - \\log \\pi_\\ell \\right).\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "### 4.1.2 Pre-jump value function\n",
    "\n",
    "The pre-jump value function has a similar structure with two exceptions:\n",
    "  -  we include the intensity function discussed earlier and \n",
    "  -  we introduce robustness concerns for both the \n",
    "intensity and distribution over the alternative $\\gamma_3^m$ coefficients.  \n",
    "\n",
    "Given these modifications, we include:\n",
    "\n",
    "\n",
    "$$\n",
    "\\mathcal J (y) \\sum_{m=1}^M g_m \\pi_m \\left[ \\phi_m(\\overline y) - \\phi(y) \\right]\n",
    "+ \\xi_r {\\mathcal J}(y)  \\sum_{m=1}^M \\pi_m \\left( 1 - g_m + g_m \\log g_m \\right)\\pi_m \n",
    "$$\n",
    "\n",
    "in the HJB and solve for pre-jump value function $\\phi(y)$ on $[0, \\overline{y}]$:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "0 = \\max_{\\tilde e}  \\min_h \\min_{\\omega_j, \\sum_{\\ell =1}^L \\omega_\\ell  = 1} \\min_{g_m \\geqslant 0}\n",
    "& - \\delta \\phi(y)    +  \\eta \\log \\tilde e    \\cr\n",
    "& + \\frac {d \\phi(y)}{d y} {\\tilde e}  \\varsigma \\cdot h  + {\\frac {(\\eta - 1)} \\delta }\\left[\\gamma_1 +  \\gamma_2 y) \\right] {\\tilde e} \\varsigma \\cdot h + {\\frac {\\xi_r} 2} h'h \\cr \n",
    "& + \\frac {d \\phi(y)}{d y}  \\sum_{\\ell=1}^L \\omega_\\ell  \\theta_\\ell {\\tilde e} + {\\frac 1 2} \\frac {d^2 \\phi(y)}{(dy)^2} |\\varsigma|^2 \\tilde e^2  \\cr\n",
    "&+ {\\frac {(\\eta - 1)} \\delta}  \\left( \\left[ \\gamma_1 + \\gamma_2 y\\right]   \\sum_{\\ell=1}^L \\omega_\\ell \\theta_\\ell {\\tilde e} + {\\frac 1 2} \\gamma_2  |\\varsigma|^2 \\tilde e^2 \\right) \\cr\n",
    "&+ \\xi_a \\sum_{\\ell = 1}^L \\omega_\\ell \\left( \\log \\omega_\\ell - \\log \\pi_\\ell \\right)\\cr\n",
    "&+ \\mathcal J (y) \\sum_{m=1}^M g_m \\pi_m \\left[ \\phi_m(\\overline y) - \\phi(y) \\right]\n",
    "+ \\xi_r {\\mathcal J}(y)  \\sum_{m=1}^M \\pi_m \\left( 1 - g_m + g_m \\log g_m \\right)\\pi_m \n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "## 4.2 Uncertain damages\n",
    "\n",
    "Here, we focus on different configuration of damage uncertainty. \n",
    "In the following computation, we keep $\\xi_a = 0.01$ as our default value and explore with different values of $\\xi_r$.\n",
    "The values we use here are $\\{+\\infty, 5, 1, 0.3\\}$.\n",
    "\n",
    "> Note: we use a baseline case when there is no distortion in weights on climate models, brownian misspecification and damage functions. \n",
    "For the baseline configuration, $\\xi_a = + \\infty$, and $\\xi_r = + \\infty$ ($100,000$ in computation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266c95cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from src.model import solve_hjb_y, solve_hjb_y_jump\n",
    "from src.utilities import find_nearest_value, solve_post_jump\n",
    "from src.simulation import simulate_jump, no_jump_simulation\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e60a5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preference\n",
    "η = 0.032\n",
    "δ = 0.01\n",
    "\n",
    "# Climate sensitivity\n",
    "θ_list = pd.read_csv('data/model144.csv', header=None).to_numpy()[:, 0] / 1000.\n",
    "πc_o = np.ones_like(θ_list) / len(θ_list)\n",
    "\n",
    "# Damage functions\n",
    "σ_y = 1.2 * np.mean(θ_list)\n",
    "y_underline = 1.5\n",
    "y_bar = 2.\n",
    "γ_1 = 1.7675 / 10000\n",
    "γ_2 = 0.0022 * 2\n",
    "γ_3 = np.linspace(0., 1. / 3, 20)\n",
    "πd_o = np.ones_like(γ_3) / len(γ_3)\n",
    "\n",
    "# capital evolution\n",
    "α = 0.115\n",
    "i_over_k = 0.09\n",
    "K0 = 85 / α\n",
    "\n",
    "# state variable\n",
    "y_step = .01\n",
    "y_grid_long = np.arange(0., 5., y_step)\n",
    "y_grid_short = np.arange(0., 2.1 + y_step, y_step)\n",
    "n_bar = find_nearest_value(y_grid_long, y_bar) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ca3833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare ϕ conditional on low, high, extreme damage\n",
    "ξ_a = 0.01\n",
    "ξ_r_list = [100_000, 5., 1., 0.3]\n",
    "if not os.path.exists(f\"data/v_list_{ξ_a}.pickle\") and not os.path.exists(f\"data/e_tilde_list_{ξ_a}.pickle\"):\n",
    "    v_list = {}\n",
    "    e_tilde_list = {}\n",
    "    for ξ_r, ξ_a in [(100_000, 100_000), (5., ξ_a), (1., ξ_a), (0.3, ξ_a)]:\n",
    "        model_args_list = []\n",
    "        for γ_3_m in γ_3:\n",
    "            model_arg = (η, δ, σ_y, y_bar, γ_1, γ_2, γ_3_m, θ_list, πc_o, ξ_r, ξ_a)\n",
    "            model_args_list.append((y_grid_long, model_arg, None, 1., 1e-8, 5_000, False))\n",
    "        v_list[ξ_r], e_tilde_list[ξ_r] = solve_post_jump(y_grid_long, γ_3, solve_hjb_y, model_args_list)\n",
    "    pickle.dump(v_list, open(f\"data/v_list_{ξ_a}.pickle\", \"wb\"))\n",
    "    pickle.dump(e_tilde_list, open(f\"data/e_tilde_list_{ξ_a}.pickle\", \"wb\"))\n",
    "\n",
    "v_list = pickle.load(open(f\"data/v_list_{ξ_a}.pickle\", \"rb\"))\n",
    "e_tilde_list = pickle.load(open(f\"data/e_tilde_list_{ξ_a}.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9939df7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(f\"data/pre_jump_res_{ξ_a}.pickle\"):\n",
    "    pre_jump_res = {}\n",
    "    ξ_r_list = [100_000, 5., 1., 0.3]\n",
    "    for ξ_r_i in ξ_r_list:\n",
    "        ϕ_list = v_list[ξ_r_i]\n",
    "        certainty_equivalent = -ξ_r_i * np.log(\n",
    "            np.average(\n",
    "                np.exp(-1. / ξ_r_i * np.array(ϕ_list)), axis=0, weights=πd_o))\n",
    "        # Change grid from 0-4 to 0-2\n",
    "        ϕ_i = np.array(\n",
    "            [temp[n_bar] * np.ones_like(y_grid_short) for temp in ϕ_list])\n",
    "\n",
    "        # Compute ϕ with jump (impose boundary condition)\n",
    "        if ξ_r_i == 100_000:\n",
    "            ξ_a = 100_000\n",
    "        else:\n",
    "            ξ_a = 0.01\n",
    "        model_args = (η, δ, σ_y, y_underline, y_bar, γ_1, γ_2, γ_3, θ_list, πc_o, ϕ_i, πd_o,\n",
    "                      ξ_r_i, ξ_r_i, ξ_a)\n",
    "        model_res = solve_hjb_y_jump(y_grid_short,\n",
    "                                     model_args,\n",
    "                                     v0=None,\n",
    "                                     ϵ=1.,\n",
    "                                     tol=1e-8,\n",
    "                                     max_iter=5_000,\n",
    "                                     print_iteration=False)\n",
    "        simulation_res = no_jump_simulation(model_res, dt=1/4)\n",
    "        pre_jump_res[ξ_r_i] = dict(model_res=model_res,\n",
    "                               simulation_res=simulation_res,\n",
    "                               certainty_equivalent=certainty_equivalent)\n",
    "    pickle.dump(pre_jump_res, open(f\"data/pre_jump_res_{ξ_a}.pickle\", \"wb\"))\n",
    "\n",
    "pre_jump_res = pickle.load(open(f\"data/pre_jump_res_{ξ_a}.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f9a7ac",
   "metadata": {},
   "source": [
    "### Robust adjustment to climate model uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb2d4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.plots import plot5\n",
    "plot5(pre_jump_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed57abe",
   "metadata": {},
   "source": [
    "> For the 144 carbon-climate dynamic models, we take as our baseline probabilities an equal weighting of all of the models. To determine whether or not this is a reasonable choice of $\\xi_a$ to use in our analysis, we examine the implied distortion to the probability distribution of $\\theta_\\ell$ values resulting from our choice as compared to the baseline prior probability distribution. Both the original prior probability distribution (red histogram) and the distorted probability distribution (blue histogram) of $\\theta_\\ell$ values are given in the plot above. The increased concern about uncertainty over the geo-scientific inputs leads to a shift to the right in the $\\theta_\\ell$ probability distribution, highlighting increased concerns about worst-case climate dynamics, while still maintaining a spread in the weights on the values of $\\theta_\\ell$ and not loading all the weight on the far right tail. We, therefore, view this shift in the distribution as reasonable to entertain. The implied mean distortion is about 0.26 for the unknown parameter $\\theta$. While the concerns about geo-scientific uncertainty are state-dependent, the distortion in the probability distribution for $\\theta$ remains roughly constant over the course of our simulations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983df0c5",
   "metadata": {},
   "source": [
    "### Robust adjustments to damage function uncertainty\n",
    "\n",
    "We next consider the penalty parameter $\\xi_r$ that governs concerns about misspecifying the Poisson jump process, including both the jump intensity and the probability distribution conditioned on a jump. Recall that we use this process to capture uncertainty of the steepness in the damage function and timing of when this steepness becomes known to the decision-maker. This uncertainty is only pertinent prior to the realization of the Poisson event. We report results for three different values of this parameter $\\xi_r = 5$, $\\xi_r = 1$, $\\xi_r = 0.3$ in Figure 6. The distorted histogram for the lowest value, $\\xi_r = 0.3$, is arguably extreme, although the other two choices seem considerably harder to dismiss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7133dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.plots import plot6\n",
    "plot6(pre_jump_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d30a4d2",
   "metadata": {},
   "source": [
    "Finally, in Figure 7, we display the probabilities that a jump will occur prior to the specified dates along the socially eﬀicient trajectory for emissions. For the mid value in our discussion, $\\xi_r = 1$, the jump is pretty much assured to happen by about one hundred years out, at which point the temperature anomaly is 2 degrees Celsius. On so-called “business as usual” trajectories, the jump probabilities will converge to one much more quickly than $\\xi_r = 1$. The no-jump trajectories for different $\\xi_r$ are displayed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1e8502",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.plots import plot7\n",
    "plot7(pre_jump_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5143b3fd",
   "metadata": {},
   "source": [
    "### Emission and anomaly trajectories\n",
    "\n",
    "The figure shows emission as a function of temperature anomaly.\n",
    "\n",
    "For $\\underline y = 1.5$ and $\\overline y = 2$, and $\\underline y = 1.75$ and $\\overline y = 2.25$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174e9353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat for 1.75 - 2.25\n",
    "y_underline_higher = 1.75\n",
    "y_bar_higher = 2.25\n",
    "# state variable\n",
    "y_step = .01\n",
    "y_grid_short_2 = np.arange(0., 2.3 + y_step, y_step)\n",
    "n_bar = find_nearest_value(y_grid_long, y_bar_higher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027c2c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# post jump value functions\n",
    "if not os.path.exists(f\"data/v175_list_{ξ_a}.pickle\") and not os.path.exists(f\"data/e175_tilde_list_{ξ_a}.pickle\"):\n",
    "    v175_list = {}\n",
    "    e175_tilde_list = {}\n",
    "    for ξ_r, ξ_a in [(100_000, 100_000), (5., 0.01), (1., 0.01), (0.3, 0.01)]:\n",
    "        model_args_list = []\n",
    "        for γ_3_m in γ_3:\n",
    "            model_arg = (η, δ, σ_y, y_bar_higher, γ_1, γ_2, γ_3_m, θ_list, πc_o,\n",
    "                         ξ_r, ξ_a)\n",
    "            model_args_list.append(\n",
    "                (y_grid_long, model_arg, None, 1., 1e-8, 5_000, False))\n",
    "        v175_list[ξ_r], e175_tilde_list[ξ_r] = solve_post_jump(\n",
    "            y_grid_long, γ_3, solve_hjb_y, model_args_list)\n",
    "    pickle.dump(v_list, open(f\"data/v175_list_{ξ_a}.pickle\", \"wb\"))\n",
    "    pickle.dump(e_tilde_list, open(f\"data/e175_tilde_list_{ξ_a}.pickle\", \"wb\"))\n",
    "v175_list = pickle.load(open(f\"data/v175_list_{ξ_a}.pickle\", \"rb\"))\n",
    "e175_tilde_list = pickle.load(open(f\"data/e175_tilde_list_{ξ_a}.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0c75a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre jump value function\n",
    "if not os.path.exists(f\"data/pre_jump175_res_{ξ_a}.pickle\"):\n",
    "    pre_jump175_res = {}\n",
    "    ξ_r_list = [100_000, 5., 1., 0.3]\n",
    "    for ξ_r_i in ξ_r_list:\n",
    "        ϕ_list = v175_list[ξ_r_i]\n",
    "        certainty_equivalent = -ξ_r_i * np.log(\n",
    "            np.average(\n",
    "                np.exp(-1. / ξ_r_i * np.array(ϕ_list)), axis=0, weights=πd_o))\n",
    "        # Change grid from 0-4 to 0-2\n",
    "        ϕ_i = np.array(\n",
    "            [temp[n_bar] * np.ones_like(y_grid_short_2) for temp in ϕ_list])\n",
    "\n",
    "        # Compute ϕ with jump (impose boundary condition)\n",
    "        if ξ_r_i == 100_000:\n",
    "            ξ_a = 100_000\n",
    "        else:\n",
    "            ξ_a = 0.01\n",
    "        model_args = (η, δ, σ_y, y_underline_higher, y_bar_higher, γ_1, γ_2, γ_3,\n",
    "                      θ_list, πc_o, ϕ_i, πd_o, ξ_r_i, ξ_r_i, ξ_a)\n",
    "        model_res = solve_hjb_y_jump(y_grid_short_2,\n",
    "                                     model_args,\n",
    "                                     v0=None,\n",
    "                                     ϵ=1.,\n",
    "                                     tol=1e-8,\n",
    "                                     max_iter=5_000,\n",
    "                                     print_iteration=False)\n",
    "        simulation_res = no_jump_simulation(model_res, dt=1 / 4)\n",
    "        pre_jump175_res[ξ_r_i] = dict(model_res=model_res,\n",
    "                                      simulation_res=simulation_res,\n",
    "                                      certainty_equivalent=certainty_equivalent)\n",
    "    pickle.dump(pre_jump175_res, open(f\"data/pre_jump175_res_{ξ_a}.pickle\", \"wb\"))\n",
    "pre_jump175_res = pickle.load(open(f\"data/pre_jump175_res_{ξ_a}.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78232586",
   "metadata": {
    "tags": [
     "hidecode"
    ]
   },
   "outputs": [],
   "source": [
    "from src.plots import plot_e_tilde\n",
    "plot_e = go.Figure()\n",
    "plot_e = plot_e_tilde(plot_e, pre_jump_res, y_grid_short_2, y_underline)\n",
    "plot_e = plot_e_tilde(plot_e, pre_jump175_res, y_grid_short_2, y_underline_higher)\n",
    "for i in range(len(ξ_r_list)):\n",
    "    plot_e.data[i][\"visible\"] = True\n",
    "    plot_e.data[i][\"showlegend\"] =True\n",
    "buttons = []\n",
    "# for \n",
    "plot_e.update_layout(\n",
    "    title=\n",
    "    r\"\"\"Figure 8 : Emissions as a function of the temperature anomaly.\n",
    "   \"\"\"\n",
    ")\n",
    "for i, (y_u, y_o) in enumerate([(y_underline, y_bar), (y_underline_higher, y_bar_higher)]):\n",
    "    # Hide all traces\n",
    "    button = dict(method='update',\n",
    "                args=[\n",
    "                    {\n",
    "                        'visible': [False] * (len(ξ_r_list)*2),\n",
    "                        'showlegend': [False] * (len(ξ_r_list)*2),\n",
    "                    },\n",
    "                ],\n",
    "                label=r'\\underline y = {} and \\bar y = {}'.format(y_u, y_o))\n",
    "    # Enable the two traces we want to see\n",
    "    for j in range(len(ξ_r_list)):\n",
    "        button['args'][0][\"visible\"][i*len(ξ_r_list) + j] = True\n",
    "        button['args'][0][\"showlegend\"][i*len(ξ_r_list) + j] = True\n",
    "    # Add step to step list\n",
    "    buttons.append(button)\n",
    "\n",
    "plot_e.update_layout(\n",
    "    updatemenus=[\n",
    "        dict(\n",
    "            type=\"buttons\",\n",
    "            direction=\"right\",\n",
    "            active=0,\n",
    "            x=0.95,\n",
    "            y=1.15,\n",
    "            buttons=buttons,\n",
    "            pad={\"r\": 10, \"t\": 10, \"b\":10},\n",
    "            showactive=True\n",
    "        )\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d621e97",
   "metadata": {},
   "source": [
    "> As we see, even in advance of gaining more information about damage function curvature, the fictitious planner embraces a substantial level of precaution due to the concerns about the unknown future damage state. In light of uncertainty concerns, the control law for emissions is about twenty percent lower when $\\xi_r = 1$ than the control law based solely on the baseline probabilities. We also see that, as the value of ξr is decreased, the caution is amplified and the choice of emissions is lowered even further. It follows that the emission trajectories for the lower control laws necessarily reach the $\\underline y = 1.5$ threshold later starting from a common initial condition (plot for control over time is provided below).\n",
    ">\n",
    "> While the 1.5 and 2 degree thresholds have dominated much of the policy discussion, there is debate as to the extent to which these are firmly backed up by evidence. For this reason, we also report the consequences of shifting the thresholds we use in our computations to $\\underline y = 1.75$ and  $\\overline y = 2.25$ in the plot above. The results for emissions are very similar, except that in comparison to $\\underline y = 1.5$ and  $\\overline y = 2$ , the control laws are shifted to the right as should be expected because of delay in when the more extreme damage function curvature is manifested."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208b82a5",
   "metadata": {},
   "source": [
    "The figure shows $\\log SCC$ as a function of temperature anomaly:\n",
    "\n",
    "$$\n",
    "\\log SCC = \\log C_0 - \\log N - \\log E + \\log \\eta - \\log (1 - \\eta)\n",
    "$$\n",
    "\n",
    "where $C_0$ is the current level of output. In this way, we can focus on the impact of emission and damage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7561549e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.plots import plot_logscc\n",
    "args_scc = (α, η, i_over_k, K0, γ_1, γ_2)\n",
    "fig_logscc = go.Figure()\n",
    "fig_logscc = plot_logscc(fig_logscc, pre_jump_res, y_grid_short, 1.5, ξ_r_list, args_scc)\n",
    "fig_logscc = plot_logscc(fig_logscc, pre_jump175_res, y_grid_short_2, 1.75, ξ_r_list, args_scc)\n",
    "for i in range(len(ξ_r_list)):\n",
    "    fig_logscc.data[i + len(ξ_r_list)][\"visible\"] = False\n",
    "    fig_logscc.data[i + len(ξ_r_list)][\"showlegend\"] = False\n",
    "buttons = []\n",
    "# for \n",
    "fig_logscc.update_layout(title=r\"$\\text{Figure 9: }\\log SCC \\text{ as a function of the temperature anomaly.}$\")\n",
    "for i, (y_u, y_o) in enumerate([(y_underline, y_bar), (y_underline_higher, y_bar_higher)]):\n",
    "    # Hide all traces\n",
    "    button = dict(method='update',\n",
    "                args=[\n",
    "                    {\n",
    "                        'visible': [False] * (len(ξ_r_list)*2),\n",
    "                        'showlegend': [False] * (len(ξ_r_list)*2),\n",
    "                    },\n",
    "                ],\n",
    "                label=r'\\underline y = {} and \\bar y = {}'.format(y_u, y_o))\n",
    "    # Enable the two traces we want to see\n",
    "    for j in range(len(ξ_r_list)):\n",
    "        button['args'][0][\"visible\"][i*len(ξ_r_list) + j] = True\n",
    "        button['args'][0][\"showlegend\"][i*len(ξ_r_list) + j] = True\n",
    "    # Add step to step list\n",
    "    buttons.append(button)\n",
    "fig_logscc.update_layout(\n",
    "    updatemenus=[\n",
    "        dict(\n",
    "            type=\"buttons\",\n",
    "            direction=\"right\",\n",
    "            active=0,\n",
    "            x=0.95,\n",
    "            y=1.15,\n",
    "            buttons=buttons,\n",
    "            pad={\"r\": 10, \"t\": 10, \"b\":10},\n",
    "            showactive=True\n",
    "        )\n",
    "    ])\n",
    "fig_logscc.update_yaxes(range=[4.4, 6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa989fc",
   "metadata": {},
   "source": [
    "> In the plot above, we see substantial values of the $\\log SCC$ in each case. The magnitudes are amplified as we increase concerns about damage function misspecification (by decreasing the value of $\\xi_r$). In particular, as a function of the temperature anomaly, the SCC for $\\xi_r = 1$ is between and twenty and thirty percent higher than when we abstract from robustness concerns. Changing the thresholds to be $\\underline y = 1.75$ and $\\overline y = 2.25$ effectively shifts the curves to the right with a corresponding smaller SCC at the initial temperature anomaly of $y = 1.1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb532797",
   "metadata": {},
   "source": [
    "### Temperature anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e7531b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.simulation import EvolutionState\n",
    "from scipy import interpolate\n",
    "\n",
    "e_grid_1 = pre_jump_res[1][\"model_res\"][\"e_tilde\"]\n",
    "e_func_pre_damage = interpolate.interp1d(y_grid_short, e_grid_1)\n",
    "e_grid_long_1 = e_tilde_list[1]\n",
    "e_func_post_damage = [interpolate.interp1d(y_grid_long, e_grid_long_1[i]) for i in range(len(γ_3))]\n",
    "\n",
    "# start simulation\n",
    "e0 = 0\n",
    "y0 = 1.1\n",
    "temp_anol0 = 1.1\n",
    "y_underline = 1.5\n",
    "y_overline = 2.\n",
    "initial_state = EvolutionState(t=0,\n",
    "                               prob=1,\n",
    "                               damage_jump_state='pre',\n",
    "                               damage_jump_loc=None,\n",
    "                               variables=[e0, y0, temp_anol0],\n",
    "                               y_underline=y_underline,\n",
    "                               y_overline=y_overline)\n",
    "\n",
    "fun_args = (e_func_pre_damage, e_func_post_damage)\n",
    "\n",
    "T = 410\n",
    "sim_res = []\n",
    "temp_anols = []\n",
    "probs = []\n",
    "damage_locs = []\n",
    "sim_res.append([initial_state])\n",
    "for i in range(T):\n",
    "    if i == 0:\n",
    "        states = initial_state.evolve(np.mean(θ_list), fun_args)\n",
    "    else:\n",
    "        temp = []\n",
    "        for state in states:\n",
    "            temp += state.evolve(np.mean(θ_list), fun_args)\n",
    "        states = temp\n",
    "    tempanol_t = []\n",
    "    probs_t = []\n",
    "    damage_loc_t = []\n",
    "    for state in states:\n",
    "        tempanol_t.append( state.variables[2] )\n",
    "        probs_t.append( state.prob )\n",
    "        damage_loc_t.append( state.damage_jump_loc )\n",
    "\n",
    "    temp_anols.append(tempanol_t)\n",
    "    probs.append(probs_t)\n",
    "    damage_locs.append(damage_loc_t)\n",
    "    sim_res.append(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a20e2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=γ_3, y=[state.variables[0] for state in sim_res[233][:20]]))\n",
    "fig.update_xaxes(range=[-0.01, 1./3], showline=True, title=r\"$\\gamma_3$\")\n",
    "fig.update_yaxes(title=\"Emissions\", range=[0, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a38913b",
   "metadata": {},
   "source": [
    "A smoother version of the relation between $\\gamma_3$ and corresponding emissions at the jump date is presented below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356f2e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare ϕ conditional on low, high, extreme damage\n",
    "ξ_r_dense = 1\n",
    "ξ_a_dense = 0.01\n",
    "γ_3_dense = np.linspace(0, 1/3, 100)\n",
    "if not os.path.exists(\"data/ems_jump_date_dense.npy\"):   \n",
    "    model_args_list = []\n",
    "    for γ_3_m in γ_3_dense:\n",
    "        model_arg = (η, δ, σ_y, y_bar, γ_1, γ_2, γ_3_m, θ_list, πc_o, ξ_r_dense, ξ_a_dense)\n",
    "        model_args_list.append((y_grid_long, model_arg, None, 1., 1e-8, 2_000, False))\n",
    "    v_list_dense, e_tilde_dense = solve_post_jump(y_grid_long, γ_3_dense, solve_hjb_y, model_args_list)\n",
    "\n",
    "    loc_2 = np.abs(y_grid_short - 2.).argmin()\n",
    "    ems_jump_date_dense = np.zeros(len(γ_3_dense))\n",
    "    for i in range(len(γ_3_dense)):\n",
    "        ems_jump_date_dense[i] = e_tilde_dense[i][loc_2]\n",
    "    np.save(\"data/ems_jump_date_dense\", ems_jump_date_dense)\n",
    "ems_jump_date_dense = np.load(\"data/ems_jump_date_dense.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a7ae7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=γ_3_dense, y=ems_jump_date_dense))\n",
    "fig.update_xaxes(range=[-0.01, 1./3], showline=True, title=r\"$\\gamma_3$\")\n",
    "fig.update_yaxes(title=\"Emissions\", range=[0, 10])\n",
    "fig.update_layout(title=\"Figure 10: Emissions choices, conditioned on a jump having occurred, for different γ3 upon realization of the jump.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5c6904",
   "metadata": {},
   "source": [
    "> We report the initial emissions, post-jump, in the plot above as a function of $\\gamma_3$ governing the curvature of the damage function for large temperature anomalies. Importantly, this function is highly convex. The realization of a very low damage function curvature is good news for the planner, resulting in an increase in emissions in contrast to many of the other damage function specifications that could be realized. For the damage functions with even a little more curvature, there is a large reduction in emissions as reflected in the steep slope of the function of optimal emissions choices for small values of $\\gamma_3$. The emissions choices are increasingly more concentrated at similar values for higher curvature, as seen in the much flatter slope for the larger values of $\\gamma_3$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61aa8ba4",
   "metadata": {},
   "source": [
    "### Emission trajectories over time\n",
    "\n",
    "The following figure shows emissions over time before temperature anomaly reaches the lower bound of jump threshold, 1.5 $^o C$.\n",
    "\n",
    "For our choice of uncertainty parameters, the damage function jumps will not be crossed in fifty to seventy years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b003890c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.plots import plot_ems_app\n",
    "ξ_r_list = [100_000, 5, 1, 0.3]\n",
    "emission_traj = plot_ems_app(pre_jump_res, y_grid_short, ξ_r_list, dt=1/4, model_res=False, truncate=True)\n",
    "emission_traj.update_yaxes(range=[0,7])\n",
    "emission_traj.update_xaxes(range=[0,70])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfd91af",
   "metadata": {},
   "source": [
    "This next plot show the emission trajectories conditioning on no jump occurs. The emission trajectories stop when the temperature anomaly reaches 2 $^o C$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1730583a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.plots import plot_ems_app\n",
    "ξ_r_list = [100_000, 5, 1, 0.3]\n",
    "emission_traj = plot_ems_app(pre_jump_res, y_grid_short, ξ_r_list, dt=1/4, model_res=False)\n",
    "emission_traj.update_yaxes(range=[0,15])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d0f9be",
   "metadata": {},
   "source": [
    "By introducing additional concerns about ambiguity, the initial SCC can be as large as 145 dollars per unit of carbon.\n",
    "For more detailed disussion about smooth ambiguity, go to next notebook for details: [Section 4. Illustrative economy Ib: smooth ambiguity](sec4_IllustrativeEconIB.ipynb)."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.10.3"
   }
  },
  "kernelspec": {
   "display_name": "macro-ann",
   "language": "python",
   "name": "macro-ann"
  },
  "source_map": [
   12,
   150,
   161,
   191,
   211,
   245,
   249,
   252,
   256,
   262,
   265,
   269,
   272,
   280,
   290,
   310,
   346,
   393,
   399,
   409,
   451,
   455,
   459,
   512,
   518,
   522,
   542,
   548,
   552,
   560,
   566,
   570,
   575
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}